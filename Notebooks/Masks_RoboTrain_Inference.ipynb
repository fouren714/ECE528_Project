{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"masks","language":"python","name":"masks"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"colab":{"name":"Masks_RoboTrain_Inference.ipynb","provenance":[],"machine_shape":"hm"}},"cells":[{"cell_type":"markdown","metadata":{"id":"a402d261"},"source":["## 0. Setup Paths"],"id":"a402d261"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_F6PIx_IWuWy","executionInfo":{"status":"ok","timestamp":1638643944084,"user_tz":420,"elapsed":20237,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}},"outputId":"58e0dc1e-4b6d-430b-8f67-6ed368fb406a"},"source":["#Run on CPU and high RAM configuration in masks enviornment\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"_F6PIx_IWuWy","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"2e52cf66","executionInfo":{"status":"ok","timestamp":1638643944085,"user_tz":420,"elapsed":4,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["import os"],"id":"2e52cf66","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"28f3f14c","executionInfo":{"status":"ok","timestamp":1638644364637,"user_tz":420,"elapsed":137,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["CUSTOM_MODEL_NAME = 'masks_ssd' \n","PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8' #name from zoo\n","PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n","TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n","LABEL_MAP_NAME = 'masks_label_map.pbtxt'"],"id":"28f3f14c","execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"3cc8108d","executionInfo":{"status":"ok","timestamp":1638643945531,"user_tz":420,"elapsed":140,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["paths = {\n","    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n","    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n","    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n","    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n","    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n","    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n","    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n","    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n","    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n","    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n","    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n","    'PROTOC_PATH':os.path.join('Tensorflow','protoc'),\n","    'SCHOOL_PATH': os.path.join('drive','MyDrive','ECE528_SchoolDrive','Project_Files')\n"," }"],"id":"3cc8108d","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ed7399ca","executionInfo":{"status":"ok","timestamp":1638643946840,"user_tz":420,"elapsed":123,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["files = {\n","    'PIPELINE_CONFIG':os.path.join(paths['SCHOOL_PATH'], 'Tensorflow','workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n","    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n","    'LABELMAP': os.path.join(paths['SCHOOL_PATH'], 'tfrecords',LABEL_MAP_NAME)\n","}"],"id":"ed7399ca","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"201a2597","executionInfo":{"status":"ok","timestamp":1638643949161,"user_tz":420,"elapsed":1441,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["for path in paths.values():\n","    if not os.path.exists(path):\n","        if os.name == 'posix':\n","            !mkdir -p {path}\n","        if os.name == 'nt':\n","            !mkdir {path}"],"id":"201a2597","execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3d76164a"},"source":["## 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD¶"],"id":"3d76164a"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8cb2f209","executionInfo":{"status":"ok","timestamp":1638643967061,"user_tz":420,"elapsed":5554,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}},"outputId":"542446e7-bd2d-4621-e4ac-4d8421a11de3"},"source":["!python -m pip install --upgrade pip"],"id":"8cb2f209","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 4.3 MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","Successfully installed pip-21.3.1\n"]}]},{"cell_type":"code","metadata":{"id":"8521269e","executionInfo":{"status":"ok","timestamp":1638643967062,"user_tz":420,"elapsed":3,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["if os.name=='nt':\n","    !pip install wget\n","    import wget"],"id":"8521269e","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6aaaa9ca","executionInfo":{"status":"ok","timestamp":1638643984083,"user_tz":420,"elapsed":17024,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}},"outputId":"ca495dd8-f7a6-4e62-f44a-b6168dfcb7c6"},"source":["if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n","    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"],"id":"6aaaa9ca","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Tensorflow/models'...\n","remote: Enumerating objects: 67735, done.\u001b[K\n","remote: Total 67735 (delta 0), reused 0 (delta 0), pack-reused 67735\u001b[K\n","Receiving objects: 100% (67735/67735), 576.31 MiB | 40.64 MiB/s, done.\n","Resolving deltas: 100% (47537/47537), done.\n"]}]},{"cell_type":"code","metadata":{"id":"e8fed841"},"source":["# Install Tensorflow Object Detection \n","if os.name=='posix':  \n","    !apt-get install protobuf-compiler\n","    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n","    \n","if os.name=='nt':\n","    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n","    wget.download(url)\n","    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n","    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n","    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n","    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n","    !cd Tensorflow/models/research/slim && pip install -e . "],"id":"e8fed841","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"e1b68147","outputId":"409d1615-158e-48ee-801d-e0d8b04ebe24"},"source":["!pip install tensorflow --upgrade"],"id":"e1b68147","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow\n","  Using cached tensorflow-2.7.0-cp39-cp39-win_amd64.whl (430.8 MB)\n","Collecting wrapt>=1.11.0\n","  Using cached wrapt-1.13.3-cp39-cp39-win_amd64.whl (34 kB)\n","Collecting wheel<1.0,>=0.32.0\n","  Using cached wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n","Collecting h5py>=2.9.0\n","  Using cached h5py-3.5.0-cp39-cp39-win_amd64.whl (2.8 MB)\n","Collecting opt-einsum>=2.3.2\n","  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n","  Using cached tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n","Collecting astunparse>=1.6.0\n","  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\ouren\\documents\\ece528_project\\masks\\lib\\site-packages (from tensorflow) (1.0.0)\n","Collecting termcolor>=1.1.0\n","  Using cached termcolor-1.1.0-py3-none-any.whl\n","Collecting grpcio<2.0,>=1.24.3\n","  Using cached grpcio-1.41.1-cp39-cp39-win_amd64.whl (3.2 MB)\n","Collecting protobuf>=3.9.2\n","  Using cached protobuf-3.19.1-cp39-cp39-win_amd64.whl (895 kB)\n","Requirement already satisfied: six>=1.12.0 in c:\\users\\ouren\\documents\\ece528_project\\masks\\lib\\site-packages (from tensorflow) (1.16.0)\n","Collecting keras-preprocessing>=1.1.1\n","  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","Collecting typing-extensions>=3.6.6\n","  Using cached typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Collecting numpy>=1.14.5\n","  Using cached numpy-1.21.4-cp39-cp39-win_amd64.whl (14.0 MB)\n","Collecting tensorflow-io-gcs-filesystem>=0.21.0\n","  Downloading tensorflow_io_gcs_filesystem-0.22.0-cp39-cp39-win_amd64.whl (1.5 MB)\n","Collecting flatbuffers<3.0,>=1.12\n","  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n","Collecting libclang>=9.0.1\n","  Using cached libclang-12.0.0-py2.py3-none-win_amd64.whl (13.1 MB)\n","Collecting gast<0.5.0,>=0.2.1\n","  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting tensorboard~=2.6\n","  Using cached tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n","Collecting google-pasta>=0.1.1\n","  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Collecting keras<2.8,>=2.7.0rc0\n","  Using cached keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n","Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\ouren\\documents\\ece528_project\\masks\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (49.2.1)\n","Collecting google-auth<3,>=1.6.3\n","  Using cached google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1\n","  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Collecting markdown>=2.6.8\n","  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n","Collecting werkzeug>=0.11.15\n","  Using cached Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n","Collecting tensorboard-plugin-wit>=1.6.0\n","  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n","Collecting requests<3,>=2.21.0\n","  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","Collecting cachetools<5.0,>=2.0.0\n","  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n","Collecting pyasn1-modules>=0.2.1\n","  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n","Collecting rsa<5,>=3.1.4\n","  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n","Collecting requests-oauthlib>=0.7.0\n","  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n","Collecting urllib3<1.27,>=1.21.1\n","  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","Collecting idna<4,>=2.5\n","  Using cached idna-3.3-py3-none-any.whl (61 kB)\n","Collecting certifi>=2017.4.17\n","  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n","Collecting charset-normalizer~=2.0.0\n","  Using cached charset_normalizer-2.0.7-py3-none-any.whl (38 kB)\n","Collecting pyasn1<0.5.0,>=0.4.6\n","  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n","Collecting oauthlib>=3.0.0\n","  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n","Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, wheel, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, wrapt, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.6.0\n","    Uninstalling keras-2.6.0:\n","      Successfully uninstalled keras-2.6.0\n","Successfully installed astunparse-1.6.3 cachetools-4.2.4 certifi-2021.10.8 charset-normalizer-2.0.7 flatbuffers-2.0 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.41.1 h5py-3.5.0 idna-3.3 keras-2.7.0 keras-preprocessing-1.1.2 libclang-12.0.0 markdown-3.3.4 numpy-1.21.4 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.22.0 termcolor-1.1.0 typing-extensions-3.10.0.2 urllib3-1.26.7 werkzeug-2.0.2 wheel-0.37.0 wrapt-1.13.3\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","object-detection 0.1 requires apache-beam, which is not installed.\n","object-detection 0.1 requires avro-python3, which is not installed.\n","object-detection 0.1 requires contextlib2, which is not installed.\n","object-detection 0.1 requires Cython, which is not installed.\n","object-detection 0.1 requires lxml, which is not installed.\n","object-detection 0.1 requires matplotlib, which is not installed.\n","object-detection 0.1 requires pillow, which is not installed.\n","tf-models-official 2.6.0 requires Cython, which is not installed.\n","tf-models-official 2.6.0 requires gin-config, which is not installed.\n","tf-models-official 2.6.0 requires google-api-python-client>=1.6.7, which is not installed.\n","tf-models-official 2.6.0 requires kaggle>=1.3.9, which is not installed.\n","tf-models-official 2.6.0 requires matplotlib, which is not installed.\n","tf-models-official 2.6.0 requires oauth2client, which is not installed.\n","tf-models-official 2.6.0 requires opencv-python-headless, which is not installed.\n","tf-models-official 2.6.0 requires Pillow, which is not installed.\n","tf-models-official 2.6.0 requires psutil>=5.4.3, which is not installed.\n","tf-models-official 2.6.0 requires py-cpuinfo>=3.3.0, which is not installed.\n","tf-models-official 2.6.0 requires pyyaml>=5.1, which is not installed.\n","tf-models-official 2.6.0 requires sacrebleu, which is not installed.\n","tf-models-official 2.6.0 requires sentencepiece, which is not installed.\n","tf-models-official 2.6.0 requires seqeval, which is not installed.\n","tf-models-official 2.6.0 requires tensorflow-addons, which is not installed.\n","tf-models-official 2.6.0 requires tensorflow-datasets, which is not installed.\n","tf-models-official 2.6.0 requires tensorflow-hub>=0.6.0, which is not installed.\n","tf-models-official 2.6.0 requires tensorflow-model-optimization>=0.4.1, which is not installed.\n","tf-models-official 2.6.0 requires tensorflow-text>=2.5.0, which is not installed.\n","pandas 1.3.4 requires pytz>=2017.3, which is not installed.\n","lvis 0.5.3 requires cycler>=0.10.0, which is not installed.\n","lvis 0.5.3 requires Cython>=0.29.12, which is not installed.\n","lvis 0.5.3 requires kiwisolver>=1.1.0, which is not installed.\n","lvis 0.5.3 requires matplotlib>=3.1.1, which is not installed.\n","lvis 0.5.3 requires opencv-python>=4.1.0.25, which is not installed.\n","object-detection 0.1 requires keras==2.6.0, but you have keras 2.7.0 which is incompatible.\n"]}]},{"cell_type":"code","metadata":{"id":"63060d38"},"source":["VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n","# Verify Installation\n","!python {VERIFICATION_SCRIPT}"],"id":"63060d38","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"c1cc08cb","outputId":"c90efc4b-02cb-4929-84d8-810ae2950add"},"source":["!pip install pyyaml\n"],"id":"c1cc08cb","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyyaml\n","  Using cached PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n","Installing collected packages: pyyaml\n","Successfully installed pyyaml-6.0\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-models-official 2.6.0 requires Cython, which is not installed.\n","tf-models-official 2.6.0 requires gin-config, which is not installed.\n","tf-models-official 2.6.0 requires google-api-python-client>=1.6.7, which is not installed.\n","tf-models-official 2.6.0 requires kaggle>=1.3.9, which is not installed.\n","tf-models-official 2.6.0 requires oauth2client, which is not installed.\n","tf-models-official 2.6.0 requires opencv-python-headless, which is not installed.\n","tf-models-official 2.6.0 requires psutil>=5.4.3, which is not installed.\n","tf-models-official 2.6.0 requires py-cpuinfo>=3.3.0, which is not installed.\n","tf-models-official 2.6.0 requires sacrebleu, which is not installed.\n","tf-models-official 2.6.0 requires sentencepiece, which is not installed.\n","tf-models-official 2.6.0 requires seqeval, which is not installed.\n","tf-models-official 2.6.0 requires tensorflow-addons, which is not installed.\n","tf-models-official 2.6.0 requires tensorflow-datasets, which is not installed.\n","tf-models-official 2.6.0 requires tensorflow-hub>=0.6.0, which is not installed.\n","tf-models-official 2.6.0 requires tensorflow-model-optimization>=0.4.1, which is not installed.\n","tf-models-official 2.6.0 requires tensorflow-text>=2.5.0, which is not installed.\n"]}]},{"cell_type":"markdown","metadata":{"id":"2711a775"},"source":["# 2. Add TF Records to path"],"id":"2711a775"},{"cell_type":"code","metadata":{"id":"298f7208"},"source":["if not os.path.exists(files['TF_RECORD_SCRIPT']):\n","    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"],"id":"298f7208","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"c3ed54bc","outputId":"69c5121d-971f-4cb0-da8d-fa16d45e6b9f"},"source":["!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.tfrecord')} \n","!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.tfrecord')} "],"id":"c3ed54bc","execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\Tensorflow\\scripts\\generate_tfrecord.py\", line 161, in <module>\n","    tf.app.run()\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\masks\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\masks\\lib\\site-packages\\absl\\app.py\", line 312, in run\n","    _run_main(main, args)\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\masks\\lib\\site-packages\\absl\\app.py\", line 258, in _run_main\n","    sys.exit(main(argv))\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\Tensorflow\\scripts\\generate_tfrecord.py\", line 148, in main\n","    examples = xml_to_csv(args.xml_dir)\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\Tensorflow\\scripts\\generate_tfrecord.py\", line 84, in xml_to_csv\n","    value = (root.find('filename').text,int(root.find('object')[0].text),int(root.find('object')[2].text),member[0].text,int(member[4][0].text),int(member[4][1].text), int(member[4][2].text),int(member[4][3].text)\n","ValueError: invalid literal for int() with base 10: 'without_mask'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\Tensorflow\\scripts\\generate_tfrecord.py\", line 161, in <module>\n","    tf.app.run()\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\masks\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\masks\\lib\\site-packages\\absl\\app.py\", line 312, in run\n","    _run_main(main, args)\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\masks\\lib\\site-packages\\absl\\app.py\", line 258, in _run_main\n","    sys.exit(main(argv))\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\Tensorflow\\scripts\\generate_tfrecord.py\", line 148, in main\n","    examples = xml_to_csv(args.xml_dir)\n","  File \"C:\\Users\\ouren\\Documents\\ECE528_Project\\Tensorflow\\scripts\\generate_tfrecord.py\", line 84, in xml_to_csv\n","    value = (root.find('filename').text,int(root.find('object')[0].text),int(root.find('object')[2].text),member[0].text,int(member[4][0].text),int(member[4][1].text), int(member[4][2].text),int(member[4][3].text)\n","ValueError: invalid literal for int() with base 10: 'with_mask'\n"]}]},{"cell_type":"code","metadata":{"id":"3f77d2b9","outputId":"01ab9789-f716-4489-e93d-00413fdbe203"},"source":["!pip install pytz\n"],"id":"3f77d2b9","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytz\n","  Using cached pytz-2021.3-py2.py3-none-any.whl (503 kB)\n","Installing collected packages: pytz\n","Successfully installed pytz-2021.3\n"]}]},{"cell_type":"markdown","metadata":{"id":"8865caf6"},"source":["# 3. Copy Model Config to training folder"],"id":"8865caf6"},{"cell_type":"code","metadata":{"id":"6d8f2e6d","executionInfo":{"status":"ok","timestamp":1638644493088,"user_tz":420,"elapsed":235,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["if os.name =='posix':\n","    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n","if os.name == 'nt':\n","    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"],"id":"6d8f2e6d","execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"3b8c8389","executionInfo":{"status":"ok","timestamp":1638644163720,"user_tz":420,"elapsed":113,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["import object_detection"],"id":"3b8c8389","execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bdad16c7"},"source":["# 4. Update Config for Transfer Learning"],"id":"bdad16c7"},{"cell_type":"code","metadata":{"id":"03518739","executionInfo":{"status":"ok","timestamp":1638644092953,"user_tz":420,"elapsed":2672,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["import tensorflow as tf\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format"],"id":"03518739","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"bace7d86","executionInfo":{"status":"ok","timestamp":1638644092954,"user_tz":420,"elapsed":6,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"],"id":"bace7d86","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"044f5e1a","executionInfo":{"status":"ok","timestamp":1638644118925,"user_tz":420,"elapsed":143,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n","    proto_str = f.read()                                                                                                                                                                                                                                          \n","    text_format.Merge(proto_str, pipeline_config)  "],"id":"044f5e1a","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdNcNd3AV5vs"},"source":[""],"id":"wdNcNd3AV5vs","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ff854d9"},"source":["pipeline_config.model.ssd.num_classes = 10 #len(labels)\n","pipeline_config.train_config.batch_size = 2\n","pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n","pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n","pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.tfrecord')]\n","pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.tfrecord')]"],"id":"6ff854d9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ea2ad96f","executionInfo":{"status":"ok","timestamp":1638641529821,"user_tz":420,"elapsed":94,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n","    f.write(config_text)   "],"id":"ea2ad96f","execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48adeb57","executionInfo":{"status":"ok","timestamp":1638644526200,"user_tz":420,"elapsed":149,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}},"outputId":"94aa5009-fccb-4c29-b75b-96ad9e5c157f"},"source":["config\n"],"id":"48adeb57","execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'eval_config': metrics_set: \"coco_detection_metrics\"\n"," use_moving_averages: false,\n"," 'eval_input_config': label_map_path: \"/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_label_map.pbtxt\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_test.tfrecord\"\n"," },\n"," 'eval_input_configs': [label_map_path: \"/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_label_map.pbtxt\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_test.tfrecord\"\n"," }\n"," ],\n"," 'model': ssd {\n","   num_classes: 3\n","   image_resizer {\n","     fixed_shape_resizer {\n","       height: 320\n","       width: 320\n","     }\n","   }\n","   feature_extractor {\n","     type: \"ssd_mobilenet_v2_fpn_keras\"\n","     depth_multiplier: 1.0\n","     min_depth: 16\n","     conv_hyperparams {\n","       regularizer {\n","         l2_regularizer {\n","           weight: 3.9999998989515007e-05\n","         }\n","       }\n","       initializer {\n","         random_normal_initializer {\n","           mean: 0.0\n","           stddev: 0.009999999776482582\n","         }\n","       }\n","       activation: RELU_6\n","       batch_norm {\n","         decay: 0.996999979019165\n","         scale: true\n","         epsilon: 0.0010000000474974513\n","       }\n","     }\n","     use_depthwise: true\n","     override_base_feature_extractor_hyperparams: true\n","     fpn {\n","       min_level: 3\n","       max_level: 7\n","       additional_layer_depth: 128\n","     }\n","   }\n","   box_coder {\n","     faster_rcnn_box_coder {\n","       y_scale: 10.0\n","       x_scale: 10.0\n","       height_scale: 5.0\n","       width_scale: 5.0\n","     }\n","   }\n","   matcher {\n","     argmax_matcher {\n","       matched_threshold: 0.5\n","       unmatched_threshold: 0.5\n","       ignore_thresholds: false\n","       negatives_lower_than_unmatched: true\n","       force_match_for_each_row: true\n","       use_matmul_gather: true\n","     }\n","   }\n","   similarity_calculator {\n","     iou_similarity {\n","     }\n","   }\n","   box_predictor {\n","     weight_shared_convolutional_box_predictor {\n","       conv_hyperparams {\n","         regularizer {\n","           l2_regularizer {\n","             weight: 3.9999998989515007e-05\n","           }\n","         }\n","         initializer {\n","           random_normal_initializer {\n","             mean: 0.0\n","             stddev: 0.009999999776482582\n","           }\n","         }\n","         activation: RELU_6\n","         batch_norm {\n","           decay: 0.996999979019165\n","           scale: true\n","           epsilon: 0.0010000000474974513\n","         }\n","       }\n","       depth: 128\n","       num_layers_before_predictor: 4\n","       kernel_size: 3\n","       class_prediction_bias_init: -4.599999904632568\n","       share_prediction_tower: true\n","       use_depthwise: true\n","     }\n","   }\n","   anchor_generator {\n","     multiscale_anchor_generator {\n","       min_level: 3\n","       max_level: 7\n","       anchor_scale: 4.0\n","       aspect_ratios: 1.0\n","       aspect_ratios: 2.0\n","       aspect_ratios: 0.5\n","       scales_per_octave: 2\n","     }\n","   }\n","   post_processing {\n","     batch_non_max_suppression {\n","       score_threshold: 9.99999993922529e-09\n","       iou_threshold: 0.6000000238418579\n","       max_detections_per_class: 100\n","       max_total_detections: 100\n","       use_static_shapes: false\n","     }\n","     score_converter: SIGMOID\n","   }\n","   normalize_loss_by_num_matches: true\n","   loss {\n","     localization_loss {\n","       weighted_smooth_l1 {\n","       }\n","     }\n","     classification_loss {\n","       weighted_sigmoid_focal {\n","         gamma: 2.0\n","         alpha: 0.25\n","       }\n","     }\n","     classification_weight: 1.0\n","     localization_weight: 1.0\n","   }\n","   encode_background_as_zeros: true\n","   normalize_loc_loss_by_codesize: true\n","   inplace_batchnorm_update: true\n","   freeze_batchnorm: false\n"," },\n"," 'train_config': batch_size: 64\n"," data_augmentation_options {\n","   random_horizontal_flip {\n","   }\n"," }\n"," data_augmentation_options {\n","   random_crop_image {\n","     min_object_covered: 0.0\n","     min_aspect_ratio: 0.75\n","     max_aspect_ratio: 3.0\n","     min_area: 0.75\n","     max_area: 1.0\n","     overlap_thresh: 0.0\n","   }\n"," }\n"," sync_replicas: true\n"," optimizer {\n","   momentum_optimizer {\n","     learning_rate {\n","       cosine_decay_learning_rate {\n","         learning_rate_base: 0.07999999821186066\n","         total_steps: 50000\n","         warmup_learning_rate: 0.026666000485420227\n","         warmup_steps: 1000\n","       }\n","     }\n","     momentum_optimizer_value: 0.8999999761581421\n","   }\n","   use_moving_average: false\n"," }\n"," fine_tune_checkpoint: \"/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n"," num_steps: 50000\n"," startup_delay_steps: 0.0\n"," replicas_to_aggregate: 8\n"," max_number_of_boxes: 100\n"," unpad_groundtruth_tensors: false\n"," fine_tune_checkpoint_type: \"detection\"\n"," fine_tune_checkpoint_version: V2,\n"," 'train_input_config': label_map_path: \"/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_label_map.pbtxt\"\n"," tf_record_input_reader {\n","   input_path: \"/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_train.tfrecord\"\n"," }}"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"8df7da3f"},"source":["# 5. Train"],"id":"8df7da3f"},{"cell_type":"code","metadata":{"id":"1b0ff88a","executionInfo":{"status":"ok","timestamp":1638644529892,"user_tz":420,"elapsed":123,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"],"id":"1b0ff88a","execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"62a318fb","executionInfo":{"status":"ok","timestamp":1638644534371,"user_tz":420,"elapsed":116,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2500\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"],"id":"62a318fb","execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11010de2","executionInfo":{"status":"ok","timestamp":1638642913074,"user_tz":420,"elapsed":86,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}},"outputId":"d4a636a2-1f6c-43c4-f5bb-a41e56677d90"},"source":["print(command)"],"id":"11010de2","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/masks_ssd --pipeline_config_path=drive/MyDrive/ECE528_SchoolDrive/Project_Files/Tensorflow/workspace/models/masks_ssd/pipeline.config --num_train_steps=2500\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f6ea2173","executionInfo":{"status":"ok","timestamp":1638693001524,"user_tz":420,"elapsed":48295188,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}},"outputId":"cdc8c10e-eaa0-4d3c-cb90-a84debd779b2"},"source":["!{command}\n"],"id":"f6ea2173","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-12-04 19:05:10.735952: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n","W1204 19:05:10.737552 140129304065920 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n","I1204 19:05:10.738955 140129304065920 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 2500\n","I1204 19:05:10.745756 140129304065920 config_util.py:552] Maybe overwriting train_steps: 2500\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I1204 19:05:10.745946 140129304065920 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W1204 19:05:10.777469 140129304065920 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_train.tfrecord']\n","I1204 19:05:10.786965 140129304065920 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_train.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_train.tfrecord']\n","I1204 19:05:10.787433 140129304065920 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_train.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1204 19:05:10.787524 140129304065920 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1204 19:05:10.787586 140129304065920 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W1204 19:05:10.790512 140129304065920 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W1204 19:05:10.818081 140129304065920 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W1204 19:05:19.272186 140129304065920 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W1204 19:05:22.973195 140129304065920 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1204 19:05:24.965687 140129304065920 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2021-12-04 19:05:27.912025: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","2021-12-04 19:06:30.266453: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W1204 19:06:30.972502 140125985277696 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 100 per-step time 19.061s\n","I1204 19:38:16.843314 140129304065920 model_lib_v2.py:700] Step 100 per-step time 19.061s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0069813672,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.153151,\n"," 'Loss/total_loss': 0.16013238,\n"," 'learning_rate': 0.0319994}\n","I1204 19:38:16.849177 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.0069813672,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.153151,\n"," 'Loss/total_loss': 0.16013238,\n"," 'learning_rate': 0.0319994}\n","INFO:tensorflow:Step 200 per-step time 18.509s\n","I1204 20:09:07.792068 140129304065920 model_lib_v2.py:700] Step 200 per-step time 18.509s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0026078958,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.15273464,\n"," 'Loss/total_loss': 0.15534253,\n"," 'learning_rate': 0.0373328}\n","I1204 20:09:07.799161 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.0026078958,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.15273464,\n"," 'Loss/total_loss': 0.15534253,\n"," 'learning_rate': 0.0373328}\n","INFO:tensorflow:Step 300 per-step time 18.676s\n","I1204 20:40:15.064824 140129304065920 model_lib_v2.py:700] Step 300 per-step time 18.676s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0014878756,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.15225396,\n"," 'Loss/total_loss': 0.15374184,\n"," 'learning_rate': 0.0426662}\n","I1204 20:40:15.065498 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.0014878756,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.15225396,\n"," 'Loss/total_loss': 0.15374184,\n"," 'learning_rate': 0.0426662}\n","INFO:tensorflow:Step 400 per-step time 18.502s\n","I1204 21:11:05.441061 140129304065920 model_lib_v2.py:700] Step 400 per-step time 18.502s\n","INFO:tensorflow:{'Loss/classification_loss': 0.00093975,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.15170988,\n"," 'Loss/total_loss': 0.15264964,\n"," 'learning_rate': 0.047999598}\n","I1204 21:11:05.445618 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.00093975,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.15170988,\n"," 'Loss/total_loss': 0.15264964,\n"," 'learning_rate': 0.047999598}\n","INFO:tensorflow:Step 500 per-step time 19.019s\n","I1204 21:42:47.102464 140129304065920 model_lib_v2.py:700] Step 500 per-step time 19.019s\n","INFO:tensorflow:{'Loss/classification_loss': 0.00069911743,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.15110318,\n"," 'Loss/total_loss': 0.1518023,\n"," 'learning_rate': 0.053333}\n","I1204 21:42:47.105668 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.00069911743,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.15110318,\n"," 'Loss/total_loss': 0.1518023,\n"," 'learning_rate': 0.053333}\n","INFO:tensorflow:Step 600 per-step time 18.559s\n","I1204 22:13:42.939729 140129304065920 model_lib_v2.py:700] Step 600 per-step time 18.559s\n","INFO:tensorflow:{'Loss/classification_loss': 0.000523558,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.15043463,\n"," 'Loss/total_loss': 0.15095818,\n"," 'learning_rate': 0.0586664}\n","I1204 22:13:42.940190 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.000523558,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.15043463,\n"," 'Loss/total_loss': 0.15095818,\n"," 'learning_rate': 0.0586664}\n","INFO:tensorflow:Step 700 per-step time 18.536s\n","I1204 22:44:36.551322 140129304065920 model_lib_v2.py:700] Step 700 per-step time 18.536s\n","INFO:tensorflow:{'Loss/classification_loss': 0.000395927,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14970508,\n"," 'Loss/total_loss': 0.150101,\n"," 'learning_rate': 0.0639998}\n","I1204 22:44:36.551788 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.000395927,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14970508,\n"," 'Loss/total_loss': 0.150101,\n"," 'learning_rate': 0.0639998}\n","INFO:tensorflow:Step 800 per-step time 18.802s\n","I1204 23:15:56.791327 140129304065920 model_lib_v2.py:700] Step 800 per-step time 18.802s\n","INFO:tensorflow:{'Loss/classification_loss': 0.00032826833,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14891548,\n"," 'Loss/total_loss': 0.14924376,\n"," 'learning_rate': 0.069333196}\n","I1204 23:15:56.791783 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.00032826833,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14891548,\n"," 'Loss/total_loss': 0.14924376,\n"," 'learning_rate': 0.069333196}\n","INFO:tensorflow:Step 900 per-step time 18.795s\n","I1204 23:47:16.284067 140129304065920 model_lib_v2.py:700] Step 900 per-step time 18.795s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0002737305,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.1480668,\n"," 'Loss/total_loss': 0.14834054,\n"," 'learning_rate': 0.074666604}\n","I1204 23:47:16.284523 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.0002737305,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.1480668,\n"," 'Loss/total_loss': 0.14834054,\n"," 'learning_rate': 0.074666604}\n","INFO:tensorflow:Step 1000 per-step time 18.733s\n","I1205 00:18:29.554842 140129304065920 model_lib_v2.py:700] Step 1000 per-step time 18.733s\n","INFO:tensorflow:{'Loss/classification_loss': 0.00022704178,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14716011,\n"," 'Loss/total_loss': 0.14738716,\n"," 'learning_rate': 0.08}\n","I1205 00:18:29.555331 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.00022704178,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14716011,\n"," 'Loss/total_loss': 0.14738716,\n"," 'learning_rate': 0.08}\n","INFO:tensorflow:Step 1100 per-step time 19.464s\n","I1205 00:50:55.981697 140129304065920 model_lib_v2.py:700] Step 1100 per-step time 19.464s\n","INFO:tensorflow:{'Loss/classification_loss': 0.00018814373,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14622182,\n"," 'Loss/total_loss': 0.14640996,\n"," 'learning_rate': 0.07999918}\n","I1205 00:50:55.982697 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.00018814373,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14622182,\n"," 'Loss/total_loss': 0.14640996,\n"," 'learning_rate': 0.07999918}\n","INFO:tensorflow:Step 1200 per-step time 20.403s\n","I1205 01:24:56.267632 140129304065920 model_lib_v2.py:700] Step 1200 per-step time 20.403s\n","INFO:tensorflow:{'Loss/classification_loss': 0.00017059688,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14528885,\n"," 'Loss/total_loss': 0.14545946,\n"," 'learning_rate': 0.079996705}\n","I1205 01:24:56.268135 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.00017059688,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14528885,\n"," 'Loss/total_loss': 0.14545946,\n"," 'learning_rate': 0.079996705}\n","INFO:tensorflow:Step 1300 per-step time 19.291s\n","I1205 01:57:05.394401 140129304065920 model_lib_v2.py:700] Step 1300 per-step time 19.291s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0001531911,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.1443619,\n"," 'Loss/total_loss': 0.14451508,\n"," 'learning_rate': 0.0799926}\n","I1205 01:57:05.394863 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.0001531911,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.1443619,\n"," 'Loss/total_loss': 0.14451508,\n"," 'learning_rate': 0.0799926}\n","INFO:tensorflow:Step 1400 per-step time 20.252s\n","I1205 02:30:50.633580 140129304065920 model_lib_v2.py:700] Step 1400 per-step time 20.252s\n","INFO:tensorflow:{'Loss/classification_loss': 0.00013625869,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14344089,\n"," 'Loss/total_loss': 0.14357714,\n"," 'learning_rate': 0.07998685}\n","I1205 02:30:50.634120 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.00013625869,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14344089,\n"," 'Loss/total_loss': 0.14357714,\n"," 'learning_rate': 0.07998685}\n","INFO:tensorflow:Step 1500 per-step time 20.317s\n","I1205 03:04:42.319577 140129304065920 model_lib_v2.py:700] Step 1500 per-step time 20.317s\n","INFO:tensorflow:{'Loss/classification_loss': 0.00012662805,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14252582,\n"," 'Loss/total_loss': 0.14265245,\n"," 'learning_rate': 0.07997945}\n","I1205 03:04:42.320057 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.00012662805,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14252582,\n"," 'Loss/total_loss': 0.14265245,\n"," 'learning_rate': 0.07997945}\n","INFO:tensorflow:Step 1600 per-step time 19.844s\n","I1205 03:37:46.711847 140129304065920 model_lib_v2.py:700] Step 1600 per-step time 19.844s\n","INFO:tensorflow:{'Loss/classification_loss': 0.00011171906,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14161667,\n"," 'Loss/total_loss': 0.14172839,\n"," 'learning_rate': 0.079970405}\n","I1205 03:37:46.712411 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.00011171906,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14161667,\n"," 'Loss/total_loss': 0.14172839,\n"," 'learning_rate': 0.079970405}\n","INFO:tensorflow:Step 1700 per-step time 20.435s\n","I1205 04:11:50.251012 140129304065920 model_lib_v2.py:700] Step 1700 per-step time 20.435s\n","INFO:tensorflow:{'Loss/classification_loss': 0.00010279112,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14071342,\n"," 'Loss/total_loss': 0.14081621,\n"," 'learning_rate': 0.07995972}\n","I1205 04:11:50.251481 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 0.00010279112,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.14071342,\n"," 'Loss/total_loss': 0.14081621,\n"," 'learning_rate': 0.07995972}\n","INFO:tensorflow:Step 1800 per-step time 20.481s\n","I1205 04:45:58.360955 140129304065920 model_lib_v2.py:700] Step 1800 per-step time 20.481s\n","INFO:tensorflow:{'Loss/classification_loss': 9.832957e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13981606,\n"," 'Loss/total_loss': 0.1399144,\n"," 'learning_rate': 0.0799474}\n","I1205 04:45:58.361599 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 9.832957e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13981606,\n"," 'Loss/total_loss': 0.1399144,\n"," 'learning_rate': 0.0799474}\n","INFO:tensorflow:Step 1900 per-step time 20.312s\n","I1205 05:19:49.587698 140129304065920 model_lib_v2.py:700] Step 1900 per-step time 20.312s\n","INFO:tensorflow:{'Loss/classification_loss': 8.918971e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13892455,\n"," 'Loss/total_loss': 0.13901374,\n"," 'learning_rate': 0.07993342}\n","I1205 05:19:49.588168 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 8.918971e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13892455,\n"," 'Loss/total_loss': 0.13901374,\n"," 'learning_rate': 0.07993342}\n","INFO:tensorflow:Step 2000 per-step time 20.000s\n","I1205 05:53:09.550426 140129304065920 model_lib_v2.py:700] Step 2000 per-step time 20.000s\n","INFO:tensorflow:{'Loss/classification_loss': 8.407749e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.1380389,\n"," 'Loss/total_loss': 0.13812298,\n"," 'learning_rate': 0.07991781}\n","I1205 05:53:09.550942 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 8.407749e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.1380389,\n"," 'Loss/total_loss': 0.13812298,\n"," 'learning_rate': 0.07991781}\n","INFO:tensorflow:Step 2100 per-step time 19.792s\n","I1205 06:26:08.772014 140129304065920 model_lib_v2.py:700] Step 2100 per-step time 19.792s\n","INFO:tensorflow:{'Loss/classification_loss': 8.182593e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13715906,\n"," 'Loss/total_loss': 0.13724089,\n"," 'learning_rate': 0.07990056}\n","I1205 06:26:08.772449 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 8.182593e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13715906,\n"," 'Loss/total_loss': 0.13724089,\n"," 'learning_rate': 0.07990056}\n","INFO:tensorflow:Step 2200 per-step time 18.405s\n","I1205 06:56:49.286993 140129304065920 model_lib_v2.py:700] Step 2200 per-step time 18.405s\n","INFO:tensorflow:{'Loss/classification_loss': 7.584509e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13628504,\n"," 'Loss/total_loss': 0.13636088,\n"," 'learning_rate': 0.07988167}\n","I1205 06:56:49.287427 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 7.584509e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13628504,\n"," 'Loss/total_loss': 0.13636088,\n"," 'learning_rate': 0.07988167}\n","INFO:tensorflow:Step 2300 per-step time 18.464s\n","I1205 07:27:35.649357 140129304065920 model_lib_v2.py:700] Step 2300 per-step time 18.464s\n","INFO:tensorflow:{'Loss/classification_loss': 7.049823e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13541676,\n"," 'Loss/total_loss': 0.13548726,\n"," 'learning_rate': 0.07986114}\n","I1205 07:27:35.649801 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 7.049823e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13541676,\n"," 'Loss/total_loss': 0.13548726,\n"," 'learning_rate': 0.07986114}\n","INFO:tensorflow:Step 2400 per-step time 18.645s\n","I1205 07:58:40.141466 140129304065920 model_lib_v2.py:700] Step 2400 per-step time 18.645s\n","INFO:tensorflow:{'Loss/classification_loss': 6.8503665e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13455428,\n"," 'Loss/total_loss': 0.13462278,\n"," 'learning_rate': 0.07983897}\n","I1205 07:58:40.141926 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 6.8503665e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13455428,\n"," 'Loss/total_loss': 0.13462278,\n"," 'learning_rate': 0.07983897}\n","INFO:tensorflow:Step 2500 per-step time 18.664s\n","I1205 08:29:46.522902 140129304065920 model_lib_v2.py:700] Step 2500 per-step time 18.664s\n","INFO:tensorflow:{'Loss/classification_loss': 6.5694054e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13369752,\n"," 'Loss/total_loss': 0.13376322,\n"," 'learning_rate': 0.079815164}\n","I1205 08:29:46.523350 140129304065920 model_lib_v2.py:701] {'Loss/classification_loss': 6.5694054e-05,\n"," 'Loss/localization_loss': 0.0,\n"," 'Loss/regularization_loss': 0.13369752,\n"," 'Loss/total_loss': 0.13376322,\n"," 'learning_rate': 0.079815164}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"g_MPEiJNYQ7k","executionInfo":{"status":"error","timestamp":1638716978348,"user_tz":420,"elapsed":23968533,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}},"outputId":"80478c6a-ba72-4ee3-c7ca-b98e13383881"},"source":["import time\n","\n","for i in range(50000):\n","  time.sleep(60)"],"id":"g_MPEiJNYQ7k","execution_count":25,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-e083a01e5722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"71362aa6"},"source":["!pip install gin-config==0.1.1"],"id":"71362aa6","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"95f7692f"},"source":["# 6. Evaluate"],"id":"95f7692f"},{"cell_type":"code","metadata":{"id":"55fc3bf5","executionInfo":{"status":"ok","timestamp":1638716981198,"user_tz":420,"elapsed":130,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"],"id":"55fc3bf5","execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a677eaa5","executionInfo":{"status":"ok","timestamp":1638716984141,"user_tz":420,"elapsed":106,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}},"outputId":"cf045ca4-7940-46ad-88aa-51ba8b8aea93"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())\n"],"id":"a677eaa5","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 12979923479226399777\n","xla_global_id: -1\n","]\n"]}]},{"cell_type":"code","metadata":{"id":"5b411e66"},"source":["print(command)"],"id":"5b411e66","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6519905d","executionInfo":{"status":"ok","timestamp":1638720908745,"user_tz":420,"elapsed":3919147,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}},"outputId":"e968fe60-61f8-44fb-813a-f0854abc95fb"},"source":["!{command}"],"id":"6519905d","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-12-05 15:10:00.111981: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W1205 15:10:00.137733 139801447143296 model_lib_v2.py:1082] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n","I1205 15:10:00.138069 139801447143296 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I1205 15:10:00.138167 139801447143296 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I1205 15:10:00.138243 139801447143296 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W1205 15:10:00.138375 139801447143296 model_lib_v2.py:1103] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_test.tfrecord']\n","I1205 15:10:00.201465 139801447143296 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_test.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_test.tfrecord']\n","I1205 15:10:00.205518 139801447143296 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/tfrecords/masks_test.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1205 15:10:00.205693 139801447143296 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1205 15:10:00.205796 139801447143296 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W1205 15:10:00.208349 139801447143296 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W1205 15:10:00.257534 139801447143296 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W1205 15:10:05.132397 139801447143296 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1205 15:10:06.539706 139801447143296 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/masks_ssd\n","I1205 15:10:09.593516 139801447143296 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/masks_ssd\n","INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/masks_ssd/ckpt-3\n","I1205 15:10:09.595861 139801447143296 checkpoint_utils.py:149] Found new checkpoint at Tensorflow/workspace/models/masks_ssd/ckpt-3\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1205 15:10:36.204331 139801447143296 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Finished eval step 0\n","I1205 15:10:36.211727 139801447143296 model_lib_v2.py:958] Finished eval step 0\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W1205 15:10:36.358131 139801447143296 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Finished eval step 100\n","I1205 15:10:44.311424 139801447143296 model_lib_v2.py:958] Finished eval step 100\n","INFO:tensorflow:Performing evaluation on 170 images.\n","I1205 15:10:50.978075 139801447143296 coco_evaluation.py:293] Performing evaluation on 170 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I1205 15:10:50.978588 139801447143296 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.01s)\n","I1205 15:10:50.991266 139801447143296 coco_tools.py:138] DONE (t=0.01s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.22s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Eval metrics at step 2000\n","I1205 15:10:51.279209 139801447143296 model_lib_v2.py:1007] Eval metrics at step 2000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: -1.000000\n","I1205 15:10:51.284155 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: -1.000000\n","I1205 15:10:51.285037 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: -1.000000\n","I1205 15:10:51.285754 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n","I1205 15:10:51.286453 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n","I1205 15:10:51.287129 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): -1.000000\n","I1205 15:10:51.287823 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: -1.000000\n","I1205 15:10:51.288461 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: -1.000000\n","I1205 15:10:51.289112 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: -1.000000\n","I1205 15:10:51.289765 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n","I1205 15:10:51.290394 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n","I1205 15:10:51.291075 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n","I1205 15:10:51.291813 139801447143296 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.000000\n","I1205 15:10:51.292404 139801447143296 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.000000\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.000002\n","I1205 15:10:51.293027 139801447143296 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.000002\n","INFO:tensorflow:\t+ Loss/regularization_loss: 0.138030\n","I1205 15:10:51.293663 139801447143296 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 0.138030\n","INFO:tensorflow:\t+ Loss/total_loss: 0.138032\n","I1205 15:10:51.294258 139801447143296 model_lib_v2.py:1010] \t+ Loss/total_loss: 0.138032\n","INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/masks_ssd\n","I1205 15:15:09.630065 139801447143296 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/masks_ssd\n","INFO:tensorflow:Timed-out waiting for a checkpoint.\n","I1205 16:15:08.705188 139801447143296 checkpoint_utils.py:203] Timed-out waiting for a checkpoint.\n"]}]},{"cell_type":"markdown","metadata":{"id":"af57ae6c"},"source":["# 7. Load From Checkpoint"],"id":"af57ae6c"},{"cell_type":"code","metadata":{"id":"c2755201"},"source":["import os\n","import tensorflow as tf\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","from object_detection.utils import config_util"],"id":"c2755201","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ef062ef1"},"source":["# Load pipeline config and build a detection model\n","configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n","detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n","\n","@tf.function\n","def detect_fn(image):\n","    image, shapes = detection_model.preprocess(image)\n","    prediction_dict = detection_model.predict(image, shapes)\n","    detections = detection_model.postprocess(prediction_dict, shapes)\n","    return detections"],"id":"ef062ef1","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1e8ace78"},"source":["# 8. Infer from MP4"],"id":"1e8ace78"},{"cell_type":"code","metadata":{"id":"a2626077"},"source":["video = '\"C:/Users/ouren/Documents/Senior Design/TFODCourse/LPCV Data/HarderVideo/7p3b_02M.mp4' #CHANGE to 5-5 video"],"id":"a2626077","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5b154e44"},"source":["cap = cv2.VideoCapture(video)\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","while cap.isOpened(): \n","    ret, frame = cap.read()\n","    image_np = np.array(frame)\n","    \n","    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","    detections = detect_fn(input_tensor)\n","    \n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                  for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    label_id_offset = 1\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","                image_np_with_detections,\n","                detections['detection_boxes'],\n","                detections['detection_classes']+label_id_offset,\n","                detections['detection_scores'],\n","                category_index,\n","                use_normalized_coordinates=True,\n","                max_boxes_to_draw=5,\n","                min_score_thresh=.8,\n","                agnostic_mode=False)\n","\n","    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n","    \n","    if cv2.waitKey(10) & 0xFF == ord('q'):\n","        cap.release()\n","        cv2.destroyAllWindows()\n","        break"],"id":"5b154e44","execution_count":null,"outputs":[]}]}