{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TFLiteCompression.ipynb","provenance":[],"authorship_tag":"ABX9TyOhGzkmaeU2YhD57UH5/A1o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BlkLcEHtBLPj"},"source":["## Post Training Full Integer Quantization\n","\n","the TF2 Object Detection API does not yet supoport quantiazation aware training for models"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BsFv4eDQB1vN","executionInfo":{"status":"ok","timestamp":1638849588903,"user_tz":420,"elapsed":27219,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}},"outputId":"889c175b-10ea-483c-8d64-b600c67d986e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"8lC4yAsRD239","executionInfo":{"status":"ok","timestamp":1638849809092,"user_tz":420,"elapsed":2790,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}}},"source":["import pandas as pd\n","import io\n","import tempfile\n","import os\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","import zipfile\n","import tempfile\n","import os"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"rPGArwWeBGYp","colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"status":"error","timestamp":1638850334756,"user_tz":420,"elapsed":1639,"user":{"displayName":"Fletcher Ouren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFFpLNMXyjyClvH8EdWNl7kDl--wzNrjAbXtZc=s64","userId":"13476841180163183520"}},"outputId":"ffbb5433-f0ba-4f23-fe32-8ef9b971268a"},"source":["def representative_data_gen():\n","  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n","    yield [input_value]\n","\n","graph = '/content/drive/MyDrive/ECE528_SchoolDrive/Project_Files/Graphs/custom_30KSteps.pb'\n","\n","\n","converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\n","    graph_def_file=graph,\n","                    # both `.pb` and `.pbtxt` files are accepted.\n","    input_arrays=['input'],\n","    input_shapes={'input' : [1, 224, 224,3]},\n","    output_arrays=['EffeceinetDetD0/Predictions/Softmax']\n",")\n","\n","\n","\n","#converter = tf.lite.TFLiteConverter.from_frozen_graph(graph)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.representative_dataset = representative_data_gen\n","# Ensure that if any ops can't be quantized, the converter throws an error\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","# Set the input and output tensors to uint8 (APIs added in r2.3)\n","converter.inference_input_type = tf.uint8\n","converter.inference_output_type = tf.uint8\n","\n","tflite_model_quant = converter.convert()"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Ignore 'tcmalloc: large alloc' warnings.\n"]},{"output_type":"error","ename":"UnicodeDecodeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDecodeError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_frozen_graph\u001b[0;34m(cls, graph_def_file, input_arrays, output_arrays, input_shapes)\u001b[0m\n\u001b[1;32m   2453\u001b[0m           \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2454\u001b[0;31m           \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2455\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_text_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDecodeError\u001b[0m: Error parsing message","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-ee9b84a10662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minput_arrays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0minput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput_arrays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EffeceinetDetD0/Predictions/Softmax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_frozen_graph\u001b[0;34m(cls, graph_def_file, input_arrays, output_arrays, input_shapes)\u001b[0m\n\u001b[1;32m   2461\u001b[0m                 \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2462\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2463\u001b[0;31m                 \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2464\u001b[0m             \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2465\u001b[0m             \u001b[0m_text_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mensure_text\u001b[0;34m(s, encoding, errors)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \"\"\"\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa2 in position 3: invalid start byte"]}]},{"cell_type":"markdown","metadata":{"id":"-B2JpdYwCYnv"},"source":["## Run TFlite files"]},{"cell_type":"code","metadata":{"id":"JMhvCwYGBh7Q"},"source":["interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n","input_type = interpreter.get_input_details()[0]['dtype']\n","print('input: ', input_type)\n","output_type = interpreter.get_output_details()[0]['dtype']\n","print('output: ', output_type)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7nflbnduDyBJ"},"source":["Full Test Images run\n"]},{"cell_type":"code","metadata":{"id":"yC-1sI-FDQ92"},"source":["# Helper function to run inference on a TFLite model\n","def run_tflite_model(tflite_file, test_image_indices):\n","  global test_images\n","\n","  # Initialize the interpreter\n","  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n","  interpreter.allocate_tensors()\n","\n","  input_details = interpreter.get_input_details()[0]\n","  output_details = interpreter.get_output_details()[0]\n","\n","  predictions = np.zeros((len(test_image_indices),), dtype=int)\n","  for i, test_image_index in enumerate(test_image_indices):\n","    test_image = test_images[test_image_index]\n","    test_label = test_labels[test_image_index]\n","\n","    # Check if the input type is quantized, then rescale input data to uint8\n","    if input_details['dtype'] == np.uint8:\n","      input_scale, input_zero_point = input_details[\"quantization\"]\n","      test_image = test_image / input_scale + input_zero_point\n","\n","    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n","    interpreter.set_tensor(input_details[\"index\"], test_image)\n","    interpreter.invoke()\n","    output = interpreter.get_tensor(output_details[\"index\"])[0]\n","\n","    predictions[i] = output.argmax()\n","\n","  return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JjdLNa_SDQDC"},"source":["Single Image Test"]},{"cell_type":"code","metadata":{"id":"lhwI8mRGEfS7"},"source":["# Helper function to evaluate a TFLite model on all images\n","def evaluate_model(tflite_file, model_type):\n","  global test_images\n","  global test_labels\n","\n","  test_image_indices = range(test_images.shape[0])\n","  predictions = run_tflite_model(tflite_file, test_image_indices)\n","\n","  accuracy = (np.sum(test_labels== predictions) * 100) / len(test_images)\n","\n","  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n","      model_type, accuracy, len(test_images)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yJUHHMCnEg8g"},"source":["evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"],"execution_count":null,"outputs":[]}]}